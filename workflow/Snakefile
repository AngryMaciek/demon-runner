##############################################################################
#
#   Snakemake workflow to run demon (deme-based oncology model)
#   
#   AUTHOR: Maciej_Bak
#   CONTACT: wsciekly.maciek@gmail.com
#   CREATED: 15-02-2022
#   LICENSE: Apache_2.0
#
##############################################################################


# import required modules/packages/functions
import glob
import itertools
from math import prod
import os
import traceback
from jinja2 import Template


# define always local rules
localrules: all, prepare_configfiles


# before the workflow starts: create the main outdir
onstart:
    os.makedirs(
        config["workflow_analysis_outdir"],
        exist_ok=True
    )


# after workflow sucess: clean snakemake timestamp
onsuccess:
    os.remove(
        os.path.join(
            config["workflow_analysis_outdir"],
            "simulations",
            ".snakemake_timestamp"
        )
    )


def CreateConfigFilesCrossProduct(wildcards, config_template):
    """Render demon config template with the parameters from YAML;
    implement Cartesian product of all possible parameters' options.

    Args:
        wildcards (snakemake wildcards): internal snakemake wildcards
        objects for this workflow; required for snakemake
    """

    demon_params = [k for k in list(config.keys()) if k.startswith("demon_")]
    variable_params = [k for k in demon_params if type(config[k]) is list]
    list_of_lists = [config[key] for key in variable_params]
    cartesian_products = [_ for _ in itertools.product(*list_of_lists)]
    N = prod([len(config[k]) for k in variable_params])
    hexnames = [hex(_).split("x")[-1].upper().rjust(4, "0") for _ in range(N)]

    for dirname, c_prod in zip(hexnames, cartesian_products):

        # create simulation dirs:
        os.makedirs(
            os.path.join(
                wildcards.outdir,
                "simulations",
                dirname
            ),
            exist_ok=False
        )

        # render the config dict first
        config_copy = dict(config) # deep copy of a Python dict
        for _ in range(len(variable_params)):
            config_copy[variable_params[_]] = c_prod[_]

        # then render the DAT template
        with open(config_template) as f:
            template = Template(f.read())
        rendered = template.render(config_copy)

        # prepare expected config for demon
        c_path = os.path.join(
            wildcards.outdir,
            "simulations",
            dirname,
            "config.dat"
        )
        with open(c_path, "w") as f:
            f.write(rendered)


checkpoint prepare_configfiles:
    """
    Prepare separate simulation config files based on the main workflow config.
    """
    output:
        DIR_simulations_outdir = directory(
            os.path.join(
                "{outdir}",
                "simulations"
            )
        )

    params:
        DAT_config_template = os.path.join(
                config["workflow_repo_path"],
                "resources",
                "template-config.dat"
        ),
        LOG_cluster_log = os.path.join(
            "{outdir}",
            "log",
            "prepare_configfiles.cluster.log"
        )

    threads: 1

    log:
        LOG_local_stdout = os.path.join(
            "{outdir}",
            "log",
            "prepare_configfiles.stdout.log"
        ),
        LOG_local_stderr = os.path.join(
            "{outdir}",
            "log",
            "prepare_configfiles.stderr.log"
        )

    benchmark:
        os.path.join(
            "{outdir}",
            "log",
            "prepare_configfiles.benchmark.log"
        )

    run:
        with open(log.LOG_local_stderr, "w") as errlogfile:
            try:
                os.makedirs(
                    os.path.join(
                        output.DIR_simulations_outdir
                    )
                )
                CreateConfigFilesCrossProduct(
                    wildcards,
                    params.DAT_config_template
                )
            except Exception:
                traceback.print_exc(file = errlogfile)
                raise Exception(
                    "Workflow error at rule: prepare_configfiles"
                )


rule run_demon:
    """
    Run demon simulations in parallel for every config separately.
    """
    input:
        BIN_demon = os.path.join(
            config["workflow_repo_path"],
            "workflow",
            "bin",
            "demon"
        ),
        DAT_config = os.path.join(
            "{outdir}",
            "simulations",
            "{simID}",
            "config.dat"
        )

    output:
        DAT_simulation_output = os.path.join(
            "{outdir}",
            "simulations",
            "{simID}",
            "output.dat"
        )

    params:
        DIR_simulation_subdir = os.path.join(
            "{outdir}",
            "simulations",
            "{simID}"
        ),
        LOG_cluster_log = os.path.join(
            "{outdir}",
            "log",
            "run_demon.{simID}.cluster.log"
        )

    threads: 1

    log:
        LOG_local_stdout = os.path.join(
            "{outdir}",
            "log",
            "run_demon.{simID}.stdout"
        ),
        LOG_local_stderr = os.path.join(
            "{outdir}",
            "log",
            "run_demon.{simID}.stderr"
        )

    benchmark:
        os.path.join(
            "{outdir}",
            "log",
            "run_demon.{simID}.benchmark.log"
        )

    shell:
        """
        {input.BIN_demon} \
        {params.DIR_simulation_subdir} \
        config.dat \
        1> {log.LOG_local_stdout} \
        2> {log.LOG_local_stderr}
        """


def aggregate_input(wildcards):
    """Collect output files after demon for a dynamic number of simulations;
    implements aggregation after checkpoint-based graph re-evaluation.

    Args:
        wildcards (snakemake wildcards): internal snakemake wildcards
        objects for this workflow; required for snakemake

    Returns:
        list: output files of a demon simulation
    """
    checkpoint_output = checkpoints.prepare_configfiles.get(
        outdir=config["workflow_analysis_outdir"]
    ).output[0]
    simulation_dirs = glob.glob(
        checkpoint_output + os.path.sep + "*" + os.path.sep
    )
    return [os.path.join(_, "output.dat") for _ in simulation_dirs]


rule all:
    """
    Target rule gathering final output of the workflow.
    """
    input:
        aggregate_input
